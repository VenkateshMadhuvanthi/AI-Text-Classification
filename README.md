# AI-Text-Classification
This repository presents a technical study on We evaluate and compare four encoder-based architectures — BERT, RoBERTa, DistilBERT, and TinyBERT — all trained on a shared dataset. The models are assessed on classification accuracy, efficiency, and inference speed to explore the trade-offs between size and performance. 
